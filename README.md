# Анализ документации и парсинг сайтов облачных провайдеров

Этот проект — набор из трёх Python-скриптов, выполненных в рамках тестового задания для MTS Web Services. Каждый скрипт решает одну из трёх задач, демонстрируя различные подходы к сбору и анализу веб-данных: от детального анализа страниц до стратегий работы с большими массивами информации и обхода сложных защит от ботов.

---

## Предварительные требования

Перед установкой убедитесь, что на вашем компьютере установлены:

- **Python 3.10+** (скрипты разрабатывались и тестировались на Python 3.12)
- **PIP** (стандартный менеджер пакетов Python, обычно идёт в комплекте)
- **Google Chrome** (требуется для работы скрипта `task3_sitemap_finder.py` для обхода защиты сайта Yandex Cloud)

---

## Установка

1. **Клонируйте или скачайте репозиторий:**

```bash
git clone <адрес_репозитория>
cd <папка_репозитория>
```

2. **Создайте и активируйте виртуальное окружение (рекомендуется):**

- На Windows:

```bash
python -m venv venv
.\venv\Scripts\activate
```

- На macOS / Linux:

```bash
python3 -m venv venv
source venv/bin/activate
```

3. **Установите все необходимые зависимости одной командой:**

```bash
pip install -r requirements.txt
```

> Эта команда автоматически установит: `requests`, `pandas`, `beautifulsoup4`, `pymorphy2`, `openpyxl`, `undetected-chromedriver`.

---

## Структура проекта

```
.
├── analysis_results/           # Папка для всех итоговых файлов (JSON, Excel)
├── downloaded_pages/           # Папка для сохранения HTML-страниц (создается task1)
├── task1_downloader.py         # Задача 1: Анализатор страниц документации
├── task2_search_simulation.py  # Задача 2: Симуляция быстрого поиска
├── task3_sitemap_finder.py     # Задача 3: Парсер Sitemap-файлов
├── requirements.txt            # Список зависимостей проекта
└── README.md                   # Этот файл
```

---

## Описание и запуск скриптов

### 1. `task1_downloader.py` — Анализатор страниц документации

**Назначение:**

Скрипт выполняет глубокий точечный анализ трёх заданных страниц документации Selectel. Он не просто скачивает страницы, а извлекает из них набор полезных для технического эксперта метрик.

**Ключевые особенности:**

- Глубокий анализ: заголовок, описание, дата последнего обновления, количество таблиц, анализ блоков кода (подсчет, определение языка)
- Поиск по ключевым словам: подсчёт упоминаний технологий (API, Terraform, Kubernetes и т.д.)
- Проверка ссылок: классификация на внутренние/внешние, проверка на работоспособность ("битые" ссылки)
- Оптимизация производительности: многопоточность (ThreadPoolExecutor), кэширование URL
- Двойной экспорт: результаты в JSON и Excel

**Запуск:**

```bash
python task1_downloader.py
```

**Результат:**
- Папка `downloaded_pages/` с HTML-файлами
- Папка `analysis_results/` с файлами `task1_analysis_results_v2.json` и `task1_analysis_results_v2.xlsx`

---

### 2. `task2_search_simulation.py` — Симуляция быстрого поиска

**Назначение:**

Демонстрирует концептуально верный подход к проблеме быстрого поиска информации в большом массиве данных через создание и использование обратного поискового индекса.

**Ключевые особенности:**

- Обратный индекс: ключ — лемма, значение — информация о документах
- Лемматизация: с помощью `pymorphy2`
- Фильтрация стоп-слов: уменьшает размер индекса, повышает релевантность
- Ранжирование: по частоте встречаемости слов из запроса
- Демонстрация: выводит время поиска (доли миллисекунды)

**Запуск:**

```bash
python task2_search_simulation.py
```

**Результат:**
- Этапы построения индекса и результаты тестовых запросов в консоли
- Индекс в `analysis_results/task2_inverted_index.json` и `analysis_results/task2_inverted_index.xlsx`

---

### 3. `task3_sitemap_finder.py` — Парсер Sitemap-файлов

**Назначение:**

Находит и полностью парсит файлы sitemap.xml для трёх облачных провайдеров (Selectel, Yandex Cloud, VK Cloud), чтобы собрать полный список URL-адресов их документации.

**Ключевые особенности и стратегия:**

- Стандартный подход: для Selectel и VK Cloud — robots.txt → sitemap.xml
- Обход защиты: для Yandex Cloud — режим "Абсолютный контроль" с использованием undetected-chromedriver
- Пользователь вручную открывает страницу sitemap в браузере для прохождения проверки
- Далее скрипт управляет браузером и парсит XML напрямую
- Надёжность: поддержка индексных sitemap и .gz архивов

**Запуск:**

```bash
python task3_sitemap_finder.py
```

> ⚠️ При обработке Yandex Cloud скрипт остановится и будет ждать вашего ручного действия в открывшемся окне браузера. Следуйте инструкциям в консоли.

**Результат:**
- Статистика по найденным URL для каждого провайдера в консоли
- Итоговые списки URL в `analysis_results/task3_documentation_urls.json` и `analysis_results/task3_documentation_urls.xlsx`

---

## Важные ограничения

- Из-за сложной защиты Yandex Cloud скрипт не является полностью автоматическим — требуется ручное вмешательство на одном из этапов
- Для работы скрипта необходим установленный браузер Google Chrome