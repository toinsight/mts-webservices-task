# -*- coding: utf-8 -*-

# --- –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ ---

# `re` - –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è "—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏" - —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–ª–æ–≤–∞.
import re
# `defaultdict`, `Counter`, `set` - –∏–∑ –º–æ–¥—É–ª—è `collections`.
# `defaultdict` - —É–¥–æ–±–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞.
# `Counter` - —Å–≤–µ—Ä—Ö—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ.
# `set` - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
from collections import defaultdict, Counter
# `time` - –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞.
import time
# `sys`, `io` - –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞, —á—Ç–æ–±—ã –æ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞–ª —Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã.
import sys
import io
# `os` - –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π (—Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫, —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º).
import os
# `pandas` - –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel.
import pandas as pd
# `json` - –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
import json

# *** –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø ‚Ññ1 –∏ ‚Ññ2: –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è ***
# –î–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ pymorphy2.
# –û–Ω–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç —Å–ª–æ–≤–∞ –∫ –∏—Ö —Å–ª–æ–≤–∞—Ä–Ω–æ–π —Ñ–æ—Ä–º–µ (–ª–µ–º–º–µ): "—Å–µ—Ä–≤–µ—Ä–∞", "—Å–µ—Ä–≤–µ—Ä–æ–º" -> "—Å–µ—Ä–≤–µ—Ä".
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞: pip install pymorphy2
try:
    from pymorphy2 import MorphAnalyzer
except ImportError:
    print("–û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ pymorphy2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ –∫–æ–º–∞–Ω–¥–æ–π: pip install pymorphy2")
    sys.exit(1)


# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª ---
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


# --- 1. –ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï –ò –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ---

# –≠—Ç–æ –Ω–∞—à "–∏–≥—Ä—É—à–µ—á–Ω—ã–π" –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏.
# –ö–ª—é—á - —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–æ–∫—É–º–µ–Ω—Ç–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - –µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.
DOCUMENTS = {
    "doc_1_vm": "—Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–∞ –≤ –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è. –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ api –∏–ª–∏ terraform.",
    "doc_2_k8s": "—É–ø—Ä–∞–≤–ª—è–µ–º—ã–π kubernetes. —Å–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞ —á–µ—Ä–µ–∑ api. –≤—ã—Å–æ–∫–∞—è –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥.",
    "doc_3_s3": "–æ–±—ä–µ–∫—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ s3. —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ api –∑–∞–ø—Ä–æ—Å–æ–≤. –µ—Å—Ç—å cli –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏.",
    "doc_4_db": "—É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö postgresql. —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ.",
    "doc_5_billing": "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ –±–∏–ª–ª–∏–Ω–≥ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å —É—Å–ª—É–≥. –æ–ø–ª–∞—Ç–∞ –ø–æ —Ñ–∞–∫—Ç—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."
}
# ---
# –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô: –°–ø–æ—Å–æ–±—ã –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã)
# –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –±—ã–ª–∏ –±—ã –ø—Ä–æ–ø–∏—Å–∞–Ω—ã –≤ –∫–æ–¥–µ. –û—Å–Ω–æ–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∏—Ö –ø–æ–ª—É—á–µ–Ω–∏—è:
# 1. –ß—Ç–µ–Ω–∏–µ –∏–∑ –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏ (.txt, .html), —Å–∫–∞—á–∞–Ω–Ω—ã–º–∏ —Ä–∞–Ω–µ–µ (–∫–∞–∫ –≤ –ß–∞—Å—Ç–∏ 1).
# 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, PostgreSQL), –≥–¥–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –∫–æ–Ω—Ç–µ–Ω—Ç.
# 3. –ü—Ä—è–º–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å –≤–µ–±-—Å–∞–π—Ç–æ–≤ –ø–æ —Å–ø–∏—Å–∫—É URL –∏–ª–∏ sitemap.xml (–≤–µ–±-–∫—Ä–∞—É–ª–∏–Ω–≥).
# ---

# *** –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø ‚Ññ3: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤ ***
# –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ (set) —Å—Ç–æ–ø-—Å–ª–æ–≤. –≠—Ç–æ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞, –Ω–µ –Ω–µ—Å—É—â–∏–µ —Å–º—ã—Å–ª–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏.
# –ò—Ö —É–¥–∞–ª–µ–Ω–∏–µ —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞ –∏ –ø–æ–≤—ã—à–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞.
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `set` –≤–º–µ—Å—Ç–æ `list` –¥–∞–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤–∞.
STOP_WORDS = {
    '–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ',
    '–≤—Å–µ', '–æ–Ω–∞', '—Ç–∞–∫', '–µ–≥–æ', '–Ω–æ', '–¥–∞', '—Ç—ã', '–∫', '—É', '–∂–µ', '–≤—ã', '–∑–∞',
    '–±—ã', '–ø–æ', '—Ç–æ–ª—å–∫–æ', '–µ–µ', '–º–Ω–µ', '–±—ã–ª–æ', '–≤–æ—Ç', '–æ—Ç', '–º–µ–Ω—è', '–µ—â–µ', '–Ω–µ—Ç',
    '–æ', '–∏–∑', '–µ–º—É', '—Ç–µ–ø–µ—Ä—å', '–∫–æ–≥–¥–∞', '–¥–∞–∂–µ', '–Ω—É', '–≤–¥—Ä—É–≥', '–ª–∏', '–µ—Å–ª–∏',
    '—É–∂–µ', '–∏–ª–∏', '–Ω–∏', '–±—ã—Ç—å', '–±—ã–ª', '–Ω–µ–≥–æ', '–¥–æ', '–≤–∞—Å', '–Ω–∏–±—É–¥—å', '–æ–ø—è—Ç—å',
    '—É–∂', '–≤–∞–º', '–≤–µ–¥—å', '—Ç–∞–º', '–ø–æ—Ç–æ–º', '—Å–µ–±—è', '–Ω–∏—á–µ–≥–æ', '–µ–π', '–º–æ–∂–µ—Ç', '–æ–Ω–∏',
    '—Ç—É—Ç', '–≥–¥–µ', '–µ—Å—Ç—å', '–Ω–∞–¥–æ', '–Ω–µ–π', '–¥–ª—è', '–º—ã', '—Ç–µ–±—è', '–∏—Ö', '—á–µ–º', '–±—ã–ª–∞'
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.
ANALYSIS_RESULTS_DIR = "analysis_results"
# *** –ò–ó–ú–ï–ù–ï–ù–ò–ï: –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ ***
JSON_RESULTS_FILE = os.path.join(ANALYSIS_RESULTS_DIR, "task2_inverted_index.json")
EXCEL_RESULTS_FILE = os.path.join(ANALYSIS_RESULTS_DIR, "task2_inverted_index.xlsx")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä. –î–µ–ª–∞–µ–º —ç—Ç–æ –æ–¥–∏–Ω —Ä–∞–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ,
# —Ç–∞–∫ –∫–∞–∫ —Å–æ–∑–¥–∞–Ω–∏–µ —ç—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ - —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è.
morph = MorphAnalyzer()


# --- 2. –£–õ–£–ß–®–ï–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –ü–û–ò–°–ö–û–í–û–ì–û –î–í–ò–ñ–ö–ê ---

def tokenize_and_lemmatize(text: str) -> list[str]:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞:
    1. –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞ (—Ç–æ–∫–µ–Ω—ã).
    2. –ü—Ä–∏–≤–æ–¥–∏—Ç —Å–ª–æ–≤–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É.
    3. –£–¥–∞–ª—è–µ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤–∞.
    4. –ü—Ä–∏–≤–æ–¥–∏—Ç –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∫ –µ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π (—Å–ª–æ–≤–∞—Ä–Ω–æ–π) —Ñ–æ—Ä–º–µ - –ª–µ–º–º–µ.
    """
    text = text.lower()
    # 1. –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±—É–∫–≤/—Ü–∏—Ñ—Ä (—Ç–æ–∫–µ–Ω—ã).
    tokens = re.findall(r'\b[a-z–∞-—è0-9]+\b', text)
    lemmas = []
    for token in tokens:
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–æ–∫–µ–Ω —Å—Ç–æ–ø-—Å–ª–æ–≤–æ–º.
        if token not in STOP_WORDS:
            # 3. –ü—Ä–∏–≤–æ–¥–∏–º —Å–ª–æ–≤–æ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫.
            lemmas.append(morph.parse(token)[0].normal_form)
    return lemmas


def build_rich_inverted_index(docs: dict[str, str]) -> defaultdict[str, dict[str, int]]:
    """
    –°–æ–∑–¥–∞–µ—Ç "–û–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –æ–±—Ä–∞—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å".
    –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –ø—Ä–æ—Å—Ç–æ–π –≤–µ—Ä—Å–∏–∏, –æ–Ω —Ö—Ä–∞–Ω–∏—Ç –Ω–µ —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç –Ω–∞–ª–∏—á–∏—è —Å–ª–æ–≤–∞,
    –Ω–æ –∏ —á–∞—Å—Ç–æ—Ç—É –µ–≥–æ —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è (TF - Term Frequency) –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ.
    –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞: { "–ª–µ–º–º–∞": { "doc_id_1": —á–∞—Å—Ç–æ—Ç–∞, "doc_id_2": —á–∞—Å—Ç–æ—Ç–∞ } }
    """
    # –í–Ω–µ—à–Ω–∏–π —Å–ª–æ–≤–∞—Ä—å: –∫–ª—é—á - –ª–µ–º–º–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–ª–æ–≤–∞—Ä—å.
    # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–ª–æ–≤–∞—Ä—å: –∫–ª—é—á - ID –¥–æ–∫—É–º–µ–Ω—Ç–∞, –∑–Ω–∞—á–µ–Ω–∏–µ - —á–∞—Å—Ç–æ—Ç–∞ –ª–µ–º–º—ã –≤ –Ω–µ–º.
    inverted_index = defaultdict(dict)
    for doc_id, text in docs.items():
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ª–µ–º–º –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞.
        lemmas = tokenize_and_lemmatize(text)
        # –° –ø–æ–º–æ—â—å—é Counter –º–≥–Ω–æ–≤–µ–Ω–Ω–æ —Å—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫–∞–∂–¥–∞—è –ª–µ–º–º–∞ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∞—Å—å –≤ —Ç–µ–∫—Å—Ç–µ.
        # –ù–∞–ø—Ä–∏–º–µ—Ä: ['—Å–æ–∑–¥–∞–Ω–∏–µ', '—Å–µ—Ä–≤–µ—Ä', 'api'] -> {'—Å–æ–∑–¥–∞–Ω–∏–µ': 1, '—Å–µ—Ä–≤–µ—Ä': 1, 'api': 1}
        lemma_counts = Counter(lemmas)
        
        for lemma, count in lemma_counts.items():
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–∞—à –∏–Ω–¥–µ–∫—Å: –¥–ª—è —ç—Ç–æ–π –ª–µ–º–º—ã, –≤ —ç—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ, —á–∞—Å—Ç–æ—Ç–∞ —Ä–∞–≤–Ω–∞ count.
            inverted_index[lemma][doc_id] = count
            
    return inverted_index


def search_and_rank(query: str, index: defaultdict[str, dict[str, int]]) -> list[tuple[str, int]]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ "–æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–º—É" –∏–Ω–¥–µ–∫—Å—É –∏ —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
    1. –ù–∞—Ö–æ–¥–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã, –≥–¥–µ –µ—Å—Ç—å –í–°–ï —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞.
    2. –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏.
    """
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ —Ç–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    query_lemmas = tokenize_and_lemmatize(query)
    if not query_lemmas:
        return []

    # --- –®–∞–≥ 1: –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ) ---
    # –ù–∞—Ö–æ–¥–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –ü–ï–†–í–ê–Ø –ª–µ–º–º–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞.
    # `.keys()` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ID –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≥–¥–µ –µ—Å—Ç—å –ª–µ–º–º–∞.
    try:
        result_doc_ids = set(index[query_lemmas[0]].keys())
    except KeyError:
        # –ï—Å–ª–∏ –¥–∞–∂–µ –ø–µ—Ä–≤–æ–π –ª–µ–º–º—ã –Ω–µ—Ç –≤ –∏–Ω–¥–µ–∫—Å–µ, —Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–æ—á–Ω–æ –Ω–µ—Ç.
        return []

    # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ "–æ—Ç—Å–µ–∫–∞–µ–º" –¥–æ–∫—É–º–µ–Ω—Ç—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –û–°–¢–ê–õ–¨–ù–´–• –ª–µ–º–º.
    # `intersection_update` - –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –Ω–∞–¥ –º–Ω–æ–∂–µ—Å—Ç–≤–∞–º–∏.
    for lemma in query_lemmas[1:]:
        if lemma in index:
            result_doc_ids.intersection_update(index[lemma].keys())
        else:
            # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–π –ª–µ–º–º—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –Ω–µ—Ç –≤ –∏–Ω–¥–µ–∫—Å–µ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –±—É–¥–µ—Ç.
            return []
    
    if not result_doc_ids:
        return []

    # --- –®–∞–≥ 2: –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ---
    # *** –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø ‚Ññ2: –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ***
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å "–æ—á–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏" –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    doc_scores = defaultdict(int)
    # –ü—Ä–æ—Å—Ç–µ–π—à–∏–π, –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è:
    # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞ = —Å—É–º–º–∞ —á–∞—Å—Ç–æ—Ç –≤—Å–µ—Ö —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –≤ —ç—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ.
    for doc_id in result_doc_ids:
        score = 0
        for lemma in query_lemmas:
            # –ë–µ—Ä–µ–º –∏–∑ –∏–Ω–¥–µ–∫—Å–∞, –∫–∞–∫ —á–∞—Å—Ç–æ —ç—Ç–∞ –ª–µ–º–º–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ, –∏ –ø—Ä–∏–±–∞–≤–ª—è–µ–º –∫ –æ—á–∫–∞–º.
            score += index[lemma][doc_id]
        doc_scores[doc_id] = score
        
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∏—Ö –æ—á–∫–∞–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é).
    sorted_docs = sorted(doc_scores.items(), key=lambda item: item[1], reverse=True)
    
    return sorted_docs


# --- 3. –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò ---
if __name__ == "__main__":
    print("--- –°–∏–º—É–ª—è—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º ---")
    
    # --- –≠–¢–ê–ü 1: –ò–ù–î–ï–ö–°–ê–¶–ò–Ø ---
    print("\n[–≠–¢–ê–ü 1] –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–≥–æ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
    start_time = time.perf_counter()
    search_index = build_rich_inverted_index(DOCUMENTS)
    end_time = time.perf_counter()
    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –¥–ª—è {len(DOCUMENTS)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å—Ç—Ä–æ–µ–Ω –∑–∞ {end_time - start_time:.6f} —Å–µ–∫—É–Ω–¥.")
    
    print("\n–ü—Ä–∏–º–µ—Ä —á–∞—Å—Ç–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (–õ–µ–º–º–∞ -> {–î–æ–∫—É–º–µ–Ω—Ç: –ß–∞—Å—Ç–æ—Ç–∞}):")
    print(f"  –õ–µ–º–º–∞ 'api' -> {search_index.get('api')}")
    print(f"  –õ–µ–º–º–∞ 'kubernetes' -> {search_index.get('kubernetes')}")
    print(f"  –õ–µ–º–º–∞ '—Å—Ç–æ–∏–º–æ—Å—Ç—å' -> {search_index.get('—Å—Ç–æ–∏–º–æ—Å—Ç—å')}")

    # --- –≠–¢–ê–ü 2: –≠–ö–°–ü–û–†–¢ –ò–ù–î–ï–ö–°–ê –í –§–ê–ô–õ–´ (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) ---
    print("\n[–≠–¢–ê–ü 2] –≠–∫—Å–ø–æ—Ä—Ç –∏–Ω–¥–µ–∫—Å–∞ –≤ —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")

    if not os.path.exists(ANALYSIS_RESULTS_DIR):
        os.makedirs(ANALYSIS_RESULTS_DIR)

    with open(JSON_RESULTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(search_index, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON: {JSON_RESULTS_FILE}")

    csv_data = []
    for lemma, doc_freqs in search_index.items():
        for doc_id, frequency in doc_freqs.items():
            csv_data.append({'lemma': lemma, 'document_id': doc_id, 'frequency': frequency})
    pd.DataFrame(csv_data).to_excel(EXCEL_RESULTS_FILE, index=False)
    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel: {EXCEL_RESULTS_FILE}")

    # --- –≠–¢–ê–ü 3: –ü–û–ò–°–ö –° –†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–ï–ú ---
    print("\n[–≠–¢–ê–ü 3] –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∏–Ω–¥–µ–∫—Å—É...\n")

    queries_to_test = [
        "API –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å",      # –ù–∞–π–¥–µ—Ç doc_3, —Ç.–∫. —Ç–∞–º –µ—Å—Ç—å –æ–±–∞ —Å–ª–æ–≤–∞
        "—Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–∞",     # –ù–∞–π–¥–µ—Ç doc_1, –±–ª–∞–≥–æ–¥–∞—Ä—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ ("—Å–µ—Ä–≤–µ—Ä–∞" -> "—Å–µ—Ä–≤–µ—Ä")
        "—Å–æ–∑–¥–∞–Ω–∏–µ api",         # –ù–∞–π–¥–µ—Ç doc_1 –∏ doc_2.
        "—É–ø—Ä–∞–≤–ª—è–µ–º—ã–π kubernetes", # –ù–∞–π–¥–µ—Ç doc_2
        "–¥–æ–∫—É–º–µ–Ω—Ç –ø—Ä–æ –±–∏–ª–ª–∏–Ω–≥", # –ù–∞–π–¥–µ—Ç doc_5, "–ø—Ä–æ" –±—É–¥–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤–æ
        "terraform"             # –ù–∞–π–¥–µ—Ç doc_1
    ]
    # ---
    # –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô: –°–ø–æ—Å–æ–±—ã –≤–≤–æ–¥–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã)
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å—ã –Ω–µ –±—ã–ª–∏ –±—ã –ø—Ä–æ–ø–∏—Å–∞–Ω—ã –≤ –∫–æ–¥–µ. –û—Å–Ω–æ–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∏—Ö –ø–æ–ª—É—á–µ–Ω–∏—è:
    # 1. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª–∏: —Å –ø–æ–º–æ—â—å—é —Ü–∏–∫–ª–∞ `while True` –∏ —Ñ—É–Ω–∫—Ü–∏–∏ `input()`.
    # 2. –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏: —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∫ `python script.py "–º–æ–π –∑–∞–ø—Ä–æ—Å"`.
    # 3. –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: —á–µ—Ä–µ–∑ API-–∑–∞–ø—Ä–æ—Å –æ—Ç —Å–∞–π—Ç–∞ —Å –ø–æ–ª–µ–º –ø–æ–∏—Å–∫–∞ (–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç).
    # ---

    for q in queries_to_test:
        start_time = time.perf_counter()
        search_results = search_and_rank(q, search_index)
        end_time = time.perf_counter()
        
        print(f"> –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: '{q}'")
        print(f"  –ù–∞–π–¥–µ–Ω–æ –∑–∞ {(end_time - start_time):.8f} —Å–µ–∫—É–Ω–¥.")
        if search_results:
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ (–¥–æ–∫—É–º–µ–Ω—Ç, –æ—á–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
            print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã (–¥–æ–∫—É–º–µ–Ω—Ç, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å): {search_results}")
        else:
            print("  –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        print("-" * 40)

    # --- –≠–¢–ê–ü 4: –í–´–í–û–î–´ –ò –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï ---
    # *** –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø ‚Ññ4: –ö—É–¥–∞ –¥–≤–∏–≥–∞—Ç—å—Å—è –¥–∞–ª—å—à–µ? ***
    print("\n[–≠–¢–ê–ü 4] –í—ã–≤–æ–¥—ã –ø–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é")
    print("""
–≠—Ç–∞ —Å–∏–º—É–ª—è—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.
–û–¥–Ω–∞–∫–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤ –º–∞—Å—à—Ç–∞–±–∞—Ö –≤—Å–µ–≥–æ –≤–µ–±–∞ –∏–ª–∏ –∫—Ä—É–ø–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏)
–∏–Ω–¥–µ–∫—Å –ø–µ—Ä–µ—Å—Ç–∞–µ—Ç –ø–æ–º–µ—â–∞—Ç—å—Å—è –≤ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—É—é –ø–∞–º—è—Ç—å –æ–¥–Ω–æ–π –º–∞—à–∏–Ω—ã.
    
–î–ª—è —Ç–∞–∫–∏—Ö –∑–∞–¥–∞—á –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –¥–≤–∏–∂–∫–∏, —Ç–∞–∫–∏–µ –∫–∞–∫:
  - Elasticsearch
  - OpenSearch
  
–û–Ω–∏ —Ä–µ—à–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –¥–∏—Å–∫–µ, –µ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä—É —Å–µ—Ä–≤–µ—Ä–æ–≤,
–æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏, –∞ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç —Å–ª–æ–∂–Ω–µ–π—à–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è (TF-IDF, BM25)
–∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ "–∏–∑ –∫–æ—Ä–æ–±–∫–∏". –≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —è–≤–ª—è–µ—Ç—Å—è –æ—Ç–ª–∏—á–Ω–æ–π –±–∞–∑–æ–π –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–æ–≥–æ,
—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç "–ø–æ–¥ –∫–∞–ø–æ—Ç–æ–º" —É —ç—Ç–∏—Ö –≥–∏–≥–∞–Ω—Ç–æ–≤.
    """)
    
    print("üéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")